import { ChatOpenAI } from '@langchain/openai';
import type { BaseChatModel } from '@langchain/core/language_models/chat_models';
import type { Embeddings } from '@langchain/core/embeddings';
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
  PromptTemplate,
} from '@langchain/core/prompts';
import {
  RunnableLambda,
  RunnableMap,
  RunnableSequence,
} from '@langchain/core/runnables';
import {
  BaseMessage,
  AIMessage,
  HumanMessage,
} from '@langchain/core/messages';
import { StringOutputParser } from '@langchain/core/output_parsers';
import LineListOutputParser from '../lib/outputParsers/listLineOutputParser';
import LineOutputParser from '../lib/outputParsers/lineOutputParser';
import { Document } from 'langchain/document';
import { searchOpenAI } from '../lib/openaiSearch';
import path from 'path';
import fs from 'fs';
import { EventEmitter } from 'events';
import { StreamEvent } from '@langchain/core/tracers/log_stream';
import { IterableReadableStream } from '@langchain/core/utils/stream';
import handleImageSearch from '../chains/imageSearchAgent';
import handleExpertSearch from '../chains/expertSearchAgent';
import { RAGDocumentChain } from '../chains/rag_document_upload';
import { webSearchRetrieverPrompt, webSearchResponsePrompt } from '../prompts/webSearch';
import axios from 'axios';

export interface MetaSearchAgentType {
  searchAndAnswer: (
    message: string,
    history: BaseMessage[],
    llm: BaseChatModel,
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    fileIds: string[],
  ) => Promise<EventEmitter>;
}

interface Config {
  activeEngines: string[];
  queryGeneratorPrompt?: string;
  responsePrompt?: string;
  rerank: boolean;
  rerankThreshold: number;
  searchWeb: boolean;
  summarizer: boolean;
  searchDatabase: boolean;
  useOpenAISearch: boolean;
  useFirecrawl?: boolean;
  searchModel?: string;
  provider?: string;
  model?: string;
  customOpenAIBaseURL?: string;
  customOpenAIKey?: string;
}

type BasicChainInput = {
  chat_history: BaseMessage[];
  query: string;
};

interface SearchResponse {
  text: string;
  sources: Array<{
    title: string;
    content: string;
    url?: string;
    source?: string;
  }>;
  illustrationImage?: string;
}

interface DocumentMetadata {
  title?: string;
  source?: string;
  fileId?: string;
  url?: string;
}

interface SearchResult {
  pageContent: string;
  metadata: {
    score?: number;
    title?: string;
    [key: string]: any;
  };
}

export class MetaSearchAgent implements MetaSearchAgentType {
  private config: Config;
  private strParser = new StringOutputParser();
  // Mise en cache des contenus des fichiers afin de limiter les acc√®s disque r√©p√©titifs
  private fileCache = new Map<string, { content: any; embeddingsData: any }>();
  private conversationHistory: BaseMessage[] = [];
  private _currentEmitter: EventEmitter | null = null;

  constructor(config: Config) {
    this.config = {
      ...config,
      useOpenAISearch: config.useOpenAISearch !== undefined ? config.useOpenAISearch : true
    };
  }

  private updateMemory(message: BaseMessage) {
    this.conversationHistory.push(message);
  }

  public getMemory(): BaseMessage[] {
    return this.conversationHistory;
  }

  /**
   * Cha√Æne de r√©cup√©ration des liens √† partir d'une requ√™te de recherche web.
   */
  private async createSearchRetrieverChain(llm: BaseChatModel) {
    // Forcer la temp√©rature √† 0 pour obtenir une r√©ponse d√©terministe
    (llm as unknown as ChatOpenAI).temperature = 0;
    return RunnableSequence.from([
      PromptTemplate.fromTemplate(webSearchRetrieverPrompt),
      llm,
      this.strParser,
      RunnableLambda.from(async (input: string) => {
        const linksOutputParser = new LineListOutputParser({ key: 'links' });
        const questionOutputParser = new LineOutputParser({ key: 'question' });

        const links = await linksOutputParser.parse(input);
        let question = this.config.summarizer
          ? await questionOutputParser.parse(input)
          : input;

        if (question === 'not_needed') {
          return { query: '', docs: [] };
        }

        let documents: Document[] = [];
        if (this.config.searchWeb) {
          console.log('üîç D√©marrage de la recherche web...');
          const res = await searchOpenAI(question, {
            language: 'fr',
            limit: 10,
            model: this.config.searchModel || 'gpt-4o-mini-search-preview-2025-03-11'
          });

          documents = res.results.map(result =>
            new Document({
              pageContent: result.content,
              metadata: {
                title: result.title,
                url: result.url,
                type: 'web',
                source: 'web',
                displayDomain: new URL(result.url).hostname.replace('www.', ''),
                favicon: result.favicon || `https://s2.googleusercontent.com/s2/favicons?domain_url=${result.url}`,
                linkText: 'Voir la page',
                ...(result.img_src && { img_src: result.img_src }),
              },
            }),
          );
          console.log('üåê Sources web trouv√©es:', documents.length);
        }
        return { query: question, docs: documents };
      }),
    ]);
  }

  /**
   * Transformation des r√©sultats d'analyse Gemini en documents compatibles avec le reste du code.
   */
  private createDocumentsFromGeminiAnalysis(
    fileIds: string[],
    response: SearchResponse
  ): Document[] {
    return fileIds.map((fileId, index) => {
      // Cr√©er un document par fichier analys√©
      return new Document({
        pageContent: response.text,
        metadata: {
          source: fileId,
          title: response.sources[index]?.title || `Document ${fileId}`,
          type: 'uploaded',
          score: 0.9,
          searchText: response.text.substring(0, 100).replace(/[\n\r]+/g, ' ').trim(),
        },
      });
    });
  }

  /**
   * Analyse les documents avec Gemini et retourne les r√©sultats sous forme de Documents.
   * Cette m√©thode remplace loadUploadedDocuments pour utiliser directement l'API Gemini.
   */
  private async analyzeDocumentsWithGemini(
    fileIds: string[],
    query: string,
    llm: BaseChatModel
  ): Promise<Document[]> {
    try {
      console.log('[GeminiAnalysis] D√©marrage analyse pour IDs:', fileIds);
      
      // V√©rifier si le mod√®le supporte l'analyse de fichiers
      if (!(llm as any).geminiFileAnalysis) {
        console.log('[GeminiAnalysis] ‚ö†Ô∏è Mod√®le incompatible, analyse directe annul√©e.');
        return [];
      }
      
      // R√©cup√©rer les chemins complets des fichiers PDF
      const uploadsDir = path.join(process.cwd(), 'uploads');
      // console.log(`[Gemini Analysis] Recherche de PDFs dans: ${uploadsDir}`); // Moins essentiel
      let filesInDir: string[] = [];
      try {
        filesInDir = fs.readdirSync(uploadsDir);
        // console.log(`[Gemini Analysis] Fichiers trouv√©s dans le dossier: ${filesInDir.length > 0 ? filesInDir.join(', ') : 'Aucun'}`); // Moins essentiel
      } catch (readDirError) {
        console.error(`[GeminiAnalysis] ‚ùå Erreur lecture dossier ${uploadsDir}:`, readDirError);
        return []; // Impossible de continuer
      }
      
      const filePaths = fileIds.map(fileId => {
        // Chercher les fichiers qui commencent par fileId et se terminent par .pdf
        const pdfFile = filesInDir.find(file => file.startsWith(fileId) && file.endsWith('.pdf'));
        
        if (pdfFile) {
          const fullPath = path.join(uploadsDir, pdfFile);
          // console.log(`[Gemini Analysis] ‚úÖ Fichier trouv√© pour ${fileId}: ${fullPath}`); // Moins essentiel
          return fullPath;
        } else {
          // console.log(`[Gemini Analysis] ‚ùì Fichier non trouv√© pour ID ${fileId} avec le pattern 'startsWith' et '.pdf'. Essai d'autres patterns...`); // Moins essentiel
          // Essayer une recherche plus flexible si la premi√®re √©choue
          const flexiblePdfFile = filesInDir.find(
            file => (file.includes(fileId) && file.endsWith('.pdf')) || file === `${fileId}.pdf`
          );
          if (flexiblePdfFile) {
            const fullPath = path.join(uploadsDir, flexiblePdfFile);
            // console.log(`[Gemini Analysis] ‚úÖ Fichier trouv√© (recherche flexible) pour ${fileId}: ${fullPath}`); // Moins essentiel
            return fullPath;
          } else {
            console.log(`[GeminiAnalysis] ‚ùå Aucun fichier PDF trouv√© pour ID ${fileId}.`);
            return null;
          }
        }
      }).filter(Boolean) as string[];
      
      if (filePaths.length === 0) {
        console.error('[GeminiAnalysis] ‚ùå Aucun chemin PDF valide trouv√©. Analyse annul√©e.');
        return [];
      }
      
      console.log(`[GeminiAnalysis] üìÑ Chemins valides trouv√©s: ${filePaths.length}`);
      console.log(`[GeminiAnalysis] üöÄ Appel API Gemini pour analyse...`);
      
      // Utiliser l'API Gemini pour analyser les fichiers
      const response = await (llm as any).geminiFileAnalysis({
        files: filePaths,
        query: `Analyse ce document en d√©tail et extrais les informations pertinentes pour r√©pondre √†: ${query}`,
        temperature: 0.2
      });
      
      console.log('[GeminiAnalysis] ‚úÖ Analyse Gemini termin√©e.');
      
      // Cr√©er la r√©ponse structur√©e
      const searchResponse: SearchResponse = {
        text: response.text,
        sources: fileIds.map(fileId => ({
          title: `Document ${fileId}`,
          content: "Document analys√© par Gemini API",
          source: fileId
        }))
      };
      
      // Convertir en documents pour compatibilit√© avec le reste du code
      const resultDocs = this.createDocumentsFromGeminiAnalysis(fileIds, searchResponse);
      console.log(`[GeminiAnalysis] üìö ${resultDocs.length} documents cr√©√©s.`);
      return resultDocs;
    } catch (error) {
      console.error('[GeminiAnalysis] ‚ùå ERREUR MAJEURE pendant analyse Gemini:', error);
      // Log plus d√©taill√© de l'erreur si disponible
      if (error instanceof Error) {
        console.error(`[GeminiAnalysis] Error Name: ${error.name}, Message: ${error.message}`);
      }
      return [];
    }
  }

  /**
   * Cha√Æne permettant de g√©n√©rer la r√©ponse finale √† partir des documents et du contexte.
   */
  private async createAnsweringChain(
    llm: BaseChatModel,
    fileIds: string[],
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
  ) {
    // console.log('[MetaSearch] Cr√©ation de la cha√Æne de r√©ponse...'); // Peut √™tre activ√© pour debug fin
    return RunnableSequence.from([
      RunnableMap.from({
        query: (input: BasicChainInput) => input.query,
        chat_history: (input: BasicChainInput) => input.chat_history,
        docs: RunnableLambda.from(async (input: BasicChainInput) => {
          // console.log('[MetaSearch] D√©but r√©cup√©ration des sources...'); // Peut √™tre activ√© pour debug fin
          let docs: Document[] = [];

          // 1. Recherche dans les documents upload√©s avec Gemini (si applicable)
          if (fileIds.length > 0 && 
              (llm as any).modelName && 
              ((llm as any).modelName.includes('gemini-1.5')) ||
               ((llm as any).modelName.includes('gemini-2.0-flash'))) {
            try {
              // Tenter l'analyse directe avec Gemini
              const uploadedDocs = await this.analyzeDocumentsWithGemini(fileIds, input.query, llm);
              console.log('[MetaSearch] R√©sultat analyse Gemini (docs): ', uploadedDocs.length);
              if (uploadedDocs.length > 0) {
                docs = uploadedDocs;
              }
            } catch (error) {
              console.error('[MetaSearch] ‚ùå Erreur analyse Gemini (dans answering chain):', error);
            }
          }

          // 2. Recherche d'experts (si activ√©e)
          if (this.config.searchDatabase) {
            try {
              // console.log('[MetaSearch] üë• Recherche d\'experts...'); // Moins essentiel
              const expertResults = await this.searchExperts(input.query, embeddings, llm);
              if (expertResults.length > 0) {
                docs = [...docs, ...expertResults];
                // console.log('[MetaSearch] Experts trouv√©s:', expertResults.length);
              }
            } catch (error) {
              console.error('[MetaSearch] ‚ùå Erreur recherche experts:', error);
            }
          }

          // 3. Recherche web (si activ√©e ET aucun fichier fourni)
          if (this.config.searchWeb && fileIds.length === 0) {
            try {
              // console.log('[MetaSearch] üåê Recherche web...'); // Moins essentiel
              const webResults = await this.performWebSearch(input.query);
              if (webResults.length > 0) {
                docs = [...docs, ...webResults];
                // console.log('[MetaSearch] R√©sultats web trouv√©s:', webResults.length);
              }
            } catch (error) {
              console.error('[MetaSearch] ‚ùå Erreur recherche web:', error);
            }
          } else if (fileIds.length > 0) {
            // console.log('[MetaSearch] üìÇ Documents pr√©sents, recherche web Firecrawl ignor√©e.');
          }

          // console.log('[MetaSearch] üîç DEBUG - Avant rerankDocs - Mode:', optimizationMode, 'Query:', input.query); // Debug d√©taill√©
          // console.log('[MetaSearch] Docs avant rerank:', docs.length); // Debug d√©taill√©
          return this.rerankDocs(
            input.query,
            docs,
            fileIds,
            embeddings,
            optimizationMode,
            llm,
            fileIds.length > 0
          );
        }).withConfig({ runName: 'FinalSourceRetriever' }),
      }),
      RunnableMap.from({
        query: (input) => input.query,
        chat_history: (input) => input.chat_history,
        date: () => new Date().toISOString(),
        context: (input) => {
          // console.log('[MetaSearch] Pr√©paration du contexte final...'); // Moins essentiel
          return this.processDocs(input.docs);
        },
        docs: (input) => input.docs,
      }),
      ChatPromptTemplate.fromMessages([
        ['system', webSearchResponsePrompt],
        new MessagesPlaceholder('chat_history'),
        ['user', '{context}\n\n{query}'],
      ]),
      llm,
      this.strParser,
    ]).withConfig({ runName: 'FinalResponseGenerator' });
  }

  /**
   * Conversion des experts en Documents.
   */
  private convertExpertsToDocuments(experts: any[]): Document[] {
    return experts.map(expert =>
      new Document({
        pageContent: `Expert: ${expert.prenom} ${expert.nom}
Sp√©cialit√©: ${expert.specialite}
Ville: ${expert.ville}
Tarif: ${expert.tarif}‚Ç¨
Expertises: ${expert.expertises}
Services: ${JSON.stringify(expert.services)}
${expert.biographie}`,
        metadata: {
          type: 'expert',
          expert: true,
          expertData: expert,
          title: `${expert.specialite} - ${expert.ville}`,
          url: `/expert/${expert.id_expert}`,
          image_url: expert.image_url
        }
      })
    );
  }

  /**
   * Recherche web √† partir de la query.
   */
  private async performWebSearch(query: string): Promise<Document[]> {
    try {
      console.log('üåê D√©marrage de la recherche web avec Firecrawl...');
      const results = await this.searchWeb(query);
      
      return results.map(result => 
        new Document({
          pageContent: result.pageContent,
          metadata: {
            title: result.metadata.title,
            url: result.metadata.url,
            type: 'web',
            source: 'web',
            displayDomain: new URL(result.metadata.url).hostname.replace('www.', ''),
            favicon: result.metadata.favicon || `https://s2.googleusercontent.com/s2/favicons?domain_url=${result.metadata.url}`,
            linkText: 'Voir la page',
            ...(result.metadata.img_src && { img_src: result.metadata.img_src }),
          },
        })
      );
    } catch (error) {
      console.error('‚ùå Erreur lors de la recherche web:', error);
      return [];
    }
  }

  /**
   * Traitement et formatage des documents pour le contexte final.
   */
  private processDocs(docs: Document[]): string {
    console.log(`üîç Traitement de ${docs.length} documents...`);
    if (docs.length === 0) {
      console.log('‚ö†Ô∏è Aucun document √† traiter');
      return "Aucun document pertinent trouv√©.";
    }
    const sortedDocs = docs.sort((a, b) => {
      if (a.metadata?.type === 'sector' && b.metadata?.type !== 'sector') return -1;
      if (a.metadata?.type !== 'sector' && b.metadata?.type === 'sector') return 1;
      return (b.metadata?.score || 0) - (a.metadata?.score || 0);
    });
    const limitedDocs = sortedDocs.slice(0, 10);
    const processedDocs = limitedDocs.map((doc, index) => {
      const source = this.formatSource(doc);
      const keyInfo = this.extractKeyInfo(doc.pageContent);
      const content = this.formatContent(doc.pageContent);
      return `=== Source ${index + 1}: ${source} ===\n${keyInfo}\n${content}\n`;
    }).join('\n\n');
    console.log(`‚úÖ ${limitedDocs.length} documents trait√©s et format√©s`);
    return processedDocs;
  }

  /**
   * Formatage de la source d'un document.
   */
  private formatSource(doc: Document): string {
    const type = doc.metadata?.type || 'unknown';
    const title = doc.metadata?.title || 'Sans titre';
    const source = doc.metadata?.source || '';
    const subsector = doc.metadata?.subsector || '';
    switch (type) {
      case 'sector':
        return `[Document Sectoriel: ${title}${subsector ? ` - ${subsector}` : ''}]`;
      case 'web':
        return `[Source Web: ${title}]`;
      default:
        return `[${title}${source ? ` - ${source}` : ''}]`;
    }
  }

  /**
   * Extraction d'informations cl√©s dans le contenu.
   */
  private extractKeyInfo(content: string): string {
    const keyPatterns = [
      /\d+(?:,\d+)?(?:\s*%|\s*euros?|\s*‚Ç¨)/g,
      /\d{4}/g,
      /\d+(?:,\d+)?\s*(?:millions?|milliards?)/g
    ];
    const keyInfo = keyPatterns
      .map(pattern => {
        const matches = content.match(pattern);
        return matches ? matches.slice(0, 5) : [];
      })
      .flat()
      .filter((v, i, a) => a.indexOf(v) === i)
      .join(', ');
    return keyInfo ? `Informations cl√©s: ${keyInfo}` : '';
  }

  /**
   * Formatage du contenu avec limitation de la taille et nettoyage.
   */
  private formatContent(content: string): string {
    const maxLength = 1500;
    const truncated = content.length > maxLength 
      ? content.substring(0, maxLength) + '...'
      : content;
    return truncated
      .replace(/\n{3,}/g, '\n\n')
      .replace(/\s{2,}/g, ' ')
      .trim();
  }

  /**
   * Fonction utilitaire de normalisation d'une source.
   */
  private normalizeSource(source: any): any {
    const isUploadedDoc = source.metadata?.type === 'uploaded';
    const isExpert = source.metadata?.type === 'expert';
    const isWeb = source.metadata?.type === 'web';
    const sourceId = source.metadata?.source;
    const pageNumber = source.metadata?.pageNumber || source.metadata?.page || 1;
    let url;
    if (isUploadedDoc && sourceId) {
      url = `/api/uploads/${sourceId}/content?page=${pageNumber}`;
    } else if (isExpert) {
      url = source.metadata?.expertData?.url || source.metadata?.url;
    } else if (isWeb) {
      url = source.metadata?.url;
    }
    let title = source.metadata?.title || '';
    if (isUploadedDoc && title) {
      title = `${title} - Page ${pageNumber}`;
    } else if (isExpert) {
      title = source.metadata?.displayTitle || title;
    }
    const limitedContent = source.pageContent?.substring(0, 1000) || '';
    return {
      pageContent: limitedContent,
      metadata: {
        title,
        type: source.metadata?.type || 'web',
        url,
        source: sourceId || (isWeb ? 'web' : undefined),
        pageNumber,
        displayDomain: isUploadedDoc
          ? 'Document local'
          : (isWeb && url ? new URL(url).hostname.replace('www.', '') : undefined),
        searchText:
          source.metadata?.searchText?.substring(0, 200) ||
          limitedContent.substring(0, 200),
        expertData: source.metadata?.expertData,
        illustrationImage: source.metadata?.illustrationImage,
        imageTitle: source.metadata?.imageTitle,
        favicon: isWeb ? `https://s2.googleusercontent.com/s2/favicons?domain_url=${url}` : source.metadata?.favicon,
        linkText: isWeb ? 'Voir la page' : 'Voir la source',
        expertName: source.metadata?.expertName,
        fileId: sourceId,
        page: pageNumber,
        isFile: isUploadedDoc,
      }
    };
  }

  /**
   * Gestion du stream d'√©v√©nements pour la g√©n√©ration des r√©ponses et des sources.
   */
  private async handleStream(
    stream: IterableReadableStream<StreamEvent>,
    emitter: EventEmitter
  ) {
    for await (const event of stream) {
      if (
        event.event === 'on_chain_end' &&
        event.name === 'FinalSourceRetriever'
      ) {
        const sources = event.data.output;
        const normalizedSources = sources?.map(this.normalizeSource) || [];
        emitter.emit(
          'data',
          JSON.stringify({
            type: 'sources',
            data: normalizedSources,
            illustrationImage: normalizedSources[0]?.metadata?.illustrationImage || null,
            imageTitle: normalizedSources[0]?.metadata?.imageTitle || null
          })
        );
      }
      if (
        event.event === 'on_chain_stream' &&
        event.name === 'FinalResponseGenerator'
      ) {
        emitter.emit(
          'data',
          JSON.stringify({ type: 'response', data: event.data.chunk })
        );
      }
      if (
        event.event === 'on_chain_end' &&
        event.name === 'FinalResponseGenerator'
      ) {
        emitter.emit('end');
      }
    }
  }

  /**
   * Gestion du stream en m√©morisant la r√©ponse compl√®te et en √©mettant des suggestions.
   */
  private async handleStreamWithMemory(
    stream: IterableReadableStream<StreamEvent>,
    emitter: EventEmitter,
    llm: BaseChatModel,
    originalQuery: string
  ) {
    let fullAssistantResponse = '';
    let hasEmittedSuggestions = false;
    let foundExperts: any[] = []; 
    
    // V√©rifier si la requ√™te est d'ordre professionnel ou entrepreneurial
    const isBusinessRelatedQuery = await this.isBusinessOrProfessionalQuery(originalQuery, llm);
    
    for await (const event of stream) {
      if (event.event === 'on_chain_stream' && event.name === 'FinalResponseGenerator') {
        fullAssistantResponse += event.data.chunk;
        emitter.emit(
          'data',
          JSON.stringify({ type: 'response', data: event.data.chunk })
        );
      } else if (event.event === 'on_chain_end') {
        if (event.name === 'FinalSourceRetriever') {
          const sources = event.data.output;
          const normalizedSources = sources?.map(this.normalizeSource) || [];
          
          // Filtrer les experts parmi les sources
          foundExperts = normalizedSources
            .filter(source => source.metadata?.type === 'expert')
            .map(source => source.metadata?.expertData)
            .filter(Boolean);
          
          console.log(`üîç Experts trouv√©s pour suggestions: ${foundExperts.length}`);
          
          emitter.emit(
            'data',
            JSON.stringify({
              type: 'sources',
              data: normalizedSources,
              illustrationImage: normalizedSources[0]?.metadata?.illustrationImage || null,
              imageTitle: normalizedSources[0]?.metadata?.imageTitle || null
            })
          );

          // G√©n√©ration imm√©diate des suggestions d√®s la r√©ception des sources
          // UNIQUEMENT si la requ√™te est d'ordre professionnel/entrepreneurial
          if (!hasEmittedSuggestions && isBusinessRelatedQuery) {
            try {
              console.log('üöÄ G√©n√©ration de suggestions IMM√âDIATE d√®s la r√©ception des sources');
              
              // Am√©lioration du prompt de suggestions bas√© sur suggestionGeneratorAgent.ts
              const suggestionPrompt = `
Vous √™tes un assistant sp√©cialis√© dans la g√©n√©ration de suggestions pour une intelligence artificielle d'entreprise.

Voici la question initiale de l'utilisateur : "${originalQuery}"

Votre t√¢che est de g√©n√©rer 4-5 suggestions de questions percutantes et pertinentes que l'utilisateur pourrait poser en compl√©ment de sa demande initiale.

INSTRUCTIONS IMPORTANTES :
- Les suggestions doivent √™tre formul√©es √† la premi√®re personne, comme si l'utilisateur les posait.
- Chaque suggestion doit se terminer par un point d'interrogation.
- Concentrez-vous sur des questions compl√©mentaires et approfondies, qui poursuivent la conversation de mani√®re naturelle.
- Proposez des questions qui explorent diff√©rents aspects li√©s au sujet initial.
- Adaptez les suggestions au domaine d'activit√© ou au contexte d√©tect√© dans la question initiale.
- Privil√©giez des suggestions pr√©cises et exploitables sur le plan professionnel.

Listez seulement les questions, sans num√©rotation, chaque suggestion sur une ligne diff√©rente.

Exemples de bonnes suggestions :
- Si la question portait sur les CGV : "Quelles clauses sp√©cifiques devrais-je inclure pour me prot√©ger contre les impay√©s ?"
- Si la question portait sur un business plan : "Comment puis-je calculer pr√©cis√©ment mon seuil de rentabilit√© ?"
- Si la question portait sur l'entrepreneuriat : "Quelles sont les aides financi√®res disponibles pour mon projet dans ma r√©gion ?"`;

              // Faire l'appel au mod√®le avec temp√©rature basse pour des suggestions plus pertinentes
              const tempModel = llm as any;
              const originalTemp = tempModel.temperature || 0.7;
              tempModel.temperature = 0.2;
              
              const suggestionsResponse = await llm.invoke(suggestionPrompt);
              
              // Restaurer la temp√©rature originale
              tempModel.temperature = originalTemp;
              
              const suggestions = String(suggestionsResponse.content)
                .split('\n')
                .filter(s => s.trim())
                .filter(s => s.includes('?')) // S'assurer que ce sont des questions
                .map(s => s.trim().replace(/^[‚Ä¢\-\s]+/, '')) // Enlever les puces ou tirets
                .slice(0, 4); // Limiter √† 4 suggestions
              
              console.log('‚úÖ Suggestions g√©n√©r√©es am√©lior√©es:', suggestions);
              
              // Format correct pour les suggestions
              emitter.emit(
                'data',
                JSON.stringify({
                  type: 'suggestions',
                  data: {
                    suggestions: suggestions,
                    suggestedExperts: foundExperts || []
                  },
                  messageId: ''  // Ce champ sera rempli c√¥t√© client avec le bon messageId
                })
              );
              hasEmittedSuggestions = true;
              console.log('‚úÖ √âv√©nement suggestions envoy√© AVANT la fin de la r√©ponse');
            } catch (error) {
              console.error('‚ùå Erreur lors de la g√©n√©ration des suggestions apr√®s sources:', error);
            }
          } else if (!isBusinessRelatedQuery) {
            console.log('‚ÑπÔ∏è Pas de suggestions g√©n√©r√©es car la requ√™te n\'est pas d\'ordre professionnel/entrepreneurial');
          }
        }
        
        if (event.name === 'FinalResponseGenerator') {
          // Comme secours, g√©n√©rer des suggestions si elles n'ont pas √©t√© g√©n√©r√©es avant
          // UNIQUEMENT si la requ√™te est d'ordre professionnel/entrepreneurial
          if (!hasEmittedSuggestions && isBusinessRelatedQuery) {
            try {
              console.log('üîÑ G√©n√©ration de suggestions de secours en fin de r√©ponse');
              
              // Utiliser le m√™me prompt am√©lior√© mais avec la r√©ponse compl√®te pour plus de contexte
              const backupSuggestionPrompt = `
Vous √™tes un assistant sp√©cialis√© dans la g√©n√©ration de suggestions pour une intelligence artificielle d'entreprise.

Voici la question initiale de l'utilisateur : "${originalQuery}"

Voici la r√©ponse qui a √©t√© donn√©e : 
"""
${fullAssistantResponse.substring(0, 1000)}
"""

Votre t√¢che est de g√©n√©rer 4-5 suggestions de questions percutantes et pertinentes que l'utilisateur pourrait poser en compl√©ment, apr√®s avoir re√ßu cette r√©ponse.

INSTRUCTIONS IMPORTANTES :
- Les suggestions doivent √™tre formul√©es √† la premi√®re personne, comme si l'utilisateur les posait.
- Chaque suggestion doit se terminer par un point d'interrogation.
- Concentrez-vous sur des questions compl√©mentaires qui approfondissent les points abord√©s dans la r√©ponse.
- Adaptez les suggestions au domaine d'activit√© ou au contexte d√©tect√©.
- Privil√©giez des suggestions pr√©cises et exploitables sur le plan professionnel.
- √âvitez les questions trop g√©n√©rales ou √©videntes.

Listez seulement les questions, sans num√©rotation, chaque suggestion sur une ligne diff√©rente.`;
              
              // Faire l'appel au mod√®le avec temp√©rature basse
              const tempModel = llm as any;
              const originalTemp = tempModel.temperature || 0.7;
              tempModel.temperature = 0.2;
              
              const suggestionsResponse = await llm.invoke(backupSuggestionPrompt);
              
              // Restaurer la temp√©rature originale
              tempModel.temperature = originalTemp;
              
              const suggestions = String(suggestionsResponse.content)
                .split('\n')
                .filter(s => s.trim())
                .filter(s => s.includes('?')) // S'assurer que ce sont des questions
                .map(s => s.trim().replace(/^[‚Ä¢\-\s]+/, '')) // Enlever les puces ou tirets
                .slice(0, 4); // Limiter √† 4 suggestions
              
              console.log('‚úÖ Suggestions de secours g√©n√©r√©es am√©lior√©es:', suggestions);
              
              // Format correct pour les suggestions
              emitter.emit(
                'data',
                JSON.stringify({
                  type: 'suggestions',
                  data: {
                    suggestions: suggestions,
                    suggestedExperts: foundExperts || []
                  },
                  messageId: ''  // Ce champ sera rempli c√¥t√© client
                })
              );
              hasEmittedSuggestions = true;
            } catch (error) {
              console.error('‚ùå Erreur lors de la g√©n√©ration des suggestions de secours:', error);
            }
          }
          
          this.updateMemory(new AIMessage(fullAssistantResponse.trim()));
          emitter.emit('end');
        }
      } else {
        emitter.emit(event.event, event.data);
      }
    }
  }

  /**
   * V√©rifie si la requ√™te est li√©e √† un contexte professionnel ou entrepreneurial
   */
  private async isBusinessOrProfessionalQuery(query: string, llm: BaseChatModel): Promise<boolean> {
    try {
      console.log('üîç V√©rification si la requ√™te est d\'ordre professionnel:', query);
      
      // Prompt pour analyser si la requ√™te est li√©e au monde professionnel ou des affaires
      const analysisPrompt = `
Analysez cette question et d√©terminez si elle est li√©e √† un contexte professionnel, entrepreneurial ou d'aide √† l'entreprise.

Question: "${query}"

√âvaluez si la question concerne l'un des domaines suivants :
- Business, entrepreneuriat, cr√©ation d'entreprise
- Gestion, management, ressources humaines
- Finance, comptabilit√©, fiscalit√©
- Marketing, vente, d√©veloppement commercial
- Droit des affaires, r√©glementation professionnelle
- Conseils professionnels ou carri√®re
- Plans d'affaires, lev√©es de fonds
- Organisation du travail, productivit√© professionnelle
- Formation professionnelle, d√©veloppement de comp√©tences en entreprise

R√©pondez strictement par "OUI" ou "NON".
`;
      
      // Utiliser une temp√©rature basse pour plus de pr√©cision
      const tempModel = llm as any;
      const originalTemp = tempModel.temperature || 0.7;
      tempModel.temperature = 0;
      
      const response = await llm.invoke(analysisPrompt);
      
      // Restaurer la temp√©rature originale
      tempModel.temperature = originalTemp;
      
      const answer = String(response.content).trim().toUpperCase();
      const isBusinessRelated = answer.includes('OUI');
      
      console.log(`üîç R√©sultat analyse requ√™te: ${isBusinessRelated ? 'Contexte professionnel' : 'Contexte non-professionnel'}`);
      return isBusinessRelated;
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse de la requ√™te:', error);
      // En cas d'erreur, par d√©faut, on consid√®re que c'est professionnel pour ne pas bloquer les suggestions
      return true;
    }
  }

  /**
   * Recherche d'experts.
   */
  private async searchExperts(
    query: string,
    embeddings: Embeddings,
    llm: BaseChatModel
  ): Promise<SearchResult[]> {
    try {
      console.log('üë• Recherche d\'experts pour:', query);
      const cleanQuery = query.replace(/[%']/g, ' ').trim();
      const expertResults = await handleExpertSearch(
        {
          query: cleanQuery,
          chat_history: [],
          messageId: 'search_' + Date.now(),
          chatId: 'chat_' + Date.now()
        },
        llm
      );
      return expertResults.experts.map(expert => ({
        pageContent: `Expert: ${expert.prenom} ${expert.nom}
Sp√©cialit√©: ${expert.specialite}
Ville: ${expert.ville}
Tarif: ${expert.tarif}‚Ç¨
Expertises: ${expert.expertises}
Services: ${JSON.stringify(expert.services)}
${expert.biographie}`,
        metadata: {
          type: 'expert',
          expert: true,
          expertData: expert,
          title: `${expert.prenom} ${expert.nom} - ${expert.specialite}`,
          url: expert.url,
          image_url: expert.image_url,
          score: 0.6
        }
      }));
    } catch (error) {
      console.error('‚ùå Erreur lors de la recherche d\'experts:', error);
      return [];
    }
  }

  /**
   * Recherche d'images.
   */
  private async handleImageSearch(query: string, llm: BaseChatModel) {
    try {
      console.log('üñºÔ∏è D√©marrage de la recherche d\'images pour:', query);
      const results = await handleImageSearch({ query, chat_history: [] }, llm);
      console.log('üñºÔ∏è R√©sultats de la recherche d\'images:', results?.length || 0, 'images trouv√©es');
      
      if (!results || !Array.isArray(results) || results.length === 0) {
        console.warn('‚ö†Ô∏è Aucun r√©sultat d\'image trouv√©, utilisation d\'une image par d√©faut');
        // Retourner une image par d√©faut si aucun r√©sultat
        return [{
          url: "https://images.unsplash.com/photo-1600880292089-90a7e086ee0c",
          alt: "Image par d√©faut",
          title: "Image par d√©faut",
          width: 800,
          height: 600,
          source: "default",
          tags: ["business", "professional", "default"],
          img_src: "https://images.unsplash.com/photo-1600880292089-90a7e086ee0c"
        }];
      }
      
      return results;
    } catch (error) {
      console.error('‚ùå Erreur lors de la recherche d\'images:', error);
      // Retourner une image par d√©faut en cas d'erreur
      return [{
        url: "https://images.unsplash.com/photo-1600880292089-90a7e086ee0c",
        alt: "Image en cas d'erreur",
        title: "Image par d√©faut (erreur)",
        width: 800,
        height: 600,
        source: "default",
        tags: ["business", "professional", "default"],
        img_src: "https://images.unsplash.com/photo-1600880292089-90a7e086ee0c"
      }];
    }
  }

  /**
   * Recherche web √† partir de la query.
   */
  private async searchWeb(query: string): Promise<SearchResult[]> {
    try {
      console.log('üåê Recherche web pour:', query);
      
      // Utiliser Firecrawl directement comme solution primaire
      if (this.config.useFirecrawl) {
        console.log('üî• Utilisation de Firecrawl pour la recherche');
        const { searchFirecrawl } = require('../lib/firecrawlSearch');

        console.log('üîÑ D√©marrage appel searchFirecrawl');
        const firecrawlResults = await searchFirecrawl(query, { 
          limit: 5,
          maxDepth: 1,
          timeLimit: 30,
          useCache: true
        });
        console.log('‚úÖ R√©sultats Firecrawl re√ßus', {
          resultCount: firecrawlResults.results?.length || 0,
          activitiesCount: firecrawlResults.activities?.length || 0,
          firstActivity: firecrawlResults.activities?.[0]?.message || 'aucune'
        });
        
        // Transmettre les activit√©s de recherche si disponibles
        if (this._currentEmitter && firecrawlResults.activities?.length > 0) {
          console.log(`üì° Transmission de ${firecrawlResults.activities.length} activit√©s Firecrawl`);
          
          // Cr√©er des activit√©s factices pour tester
          const testActivities = [
            {
              type: 'search',
              status: 'completed',
              message: 'Test de recherche',
              timestamp: new Date().toISOString(),
              depth: 1,
              maxDepth: 2
            },
            {
              type: 'analyze',
              status: 'in_progress',
              message: 'Analyse en cours',
              timestamp: new Date().toISOString(), 
              depth: 1,
              maxDepth: 2
            }
          ];
          
          console.log('üß™ Ajout de 2 activit√©s de test');
          
          // Transmettre chaque activit√© individuellement (incluant les tests)
          [...testActivities, ...firecrawlResults.activities].forEach((activity: any, index: number) => {
            console.log(`üì§ Envoi activit√© ${index+1}:`, activity.type, activity.message);
            
            try {
              this._currentEmitter.emit(
                'data',
                JSON.stringify({
                  type: 'researchActivity',
                  data: activity
                })
              );
              console.log(`‚úÖ Activit√© ${index+1} envoy√©e`);
            } catch (error) {
              console.error(`‚ùå Erreur lors de l'envoi de l'activit√© ${index+1}:`, error);
            }
          });
        } else {
          console.log('‚ö†Ô∏è Impossible de transmettre les activit√©s:', {
            hasEmitter: !!this._currentEmitter,
            activitiesCount: firecrawlResults.activities?.length || 0
          });
        }
        
        return firecrawlResults.results.map(result => ({
          pageContent: result.content,
          metadata: {
            title: result.title,
            url: result.url,
            type: 'web',
            score: 0.8,
            ...(result.img_src && { img_src: result.img_src }),
            favicon: result.favicon || `https://s2.googleusercontent.com/s2/favicons?domain_url=${result.url || 'https://firecrawl.dev'}`
          }
        }));
      }
      
      // Si Firecrawl n'est pas configur√©, utiliser OpenAI search en dernier recours
      if (this.config.useOpenAISearch) {
        try {
          console.log('‚ÑπÔ∏è Utilisation d\'OpenAI search comme solution de repli');
          const res = await searchOpenAI(query, {
            language: 'fr',
            limit: 10,
            model: this.config.searchModel || 'gpt-4o-mini'
          });
          
          return res.results.map(result => ({
            pageContent: result.content,
            metadata: {
              title: result.title,
              url: result.url,
              type: 'web',
              score: 0.4,
              ...(result.img_src && { img_src: result.img_src }),
            }
          }));
        } catch (openaiError) {
          console.error('‚ùå Erreur lors de la recherche OpenAI:', openaiError);
          if (axios.isAxiosError(openaiError)) {
            console.error('‚ùå D√©tails de l\'erreur Axios:');
            console.error(`  Status: ${openaiError.response?.status}`);
            console.error(`  Message: ${openaiError.message}`);
            console.error(`  Donn√©es: ${JSON.stringify(openaiError.response?.data || {})}`);
          }
          
          // Si OpenAI √©choue, g√©n√©rer des r√©sultats simul√©s
          const { generateSimulatedResults } = require('../lib/firecrawlSearch');
          const simResults = generateSimulatedResults(query);
          return simResults.results.map(result => ({
            pageContent: result.content,
            metadata: {
              title: result.title,
              url: result.url,
              type: 'web',
              score: 0.3,
              favicon: result.favicon
            }
          }));
        }
      }
      
      // Aucune option n'est configur√©e, renvoyer un tableau vide
      return [];
    } catch (error) {
      console.error('‚ùå Erreur lors de la recherche web:', error);
      return [];
    }
  }

  /**
   * Ex√©cution parall√®le des recherches (images, experts, web) avec Promise.allSettled.
   */
  private async parallelSearchOperations(
    query: string,
    llm: BaseChatModel,
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    hasUploadedDocs: boolean = false
  ): Promise<{
    images: any[];
    experts: SearchResult[];
    webResults: SearchResult[];
  }> {
    console.log('üîÑ D√©marrage des recherches parall√®les');
    const searchTasks = {
      // Toujours chercher des images, quel que soit le mode d'optimisation
      images: this.handleImageSearch(query, llm),
      experts: this.config.searchDatabase
        ? this.searchExperts(query, embeddings, llm)
        : Promise.resolve([]),
      // Ne pas faire de recherche web si des documents sont charg√©s
      webResults: (!hasUploadedDocs && this.config.searchWeb)
        ? this.searchWeb(query)
        : Promise.resolve([])
    };
    const results = await Promise.allSettled([
      searchTasks.images,
      searchTasks.experts,
      searchTasks.webResults
    ]);
    const images = results[0].status === 'fulfilled' ? results[0].value : [];
    const experts = results[1].status === 'fulfilled' ? results[1].value : [];
    const webResults = results[2].status === 'fulfilled' ? results[2].value : [];
    console.log('‚úÖ Recherches parall√®les termin√©es', {
      images: images?.length,
      experts: experts.length,
      webResults: webResults.length
    });
    return { images, experts, webResults };
  }

  /**
   * R√©affectation des scores et enrichissement des documents avec les r√©sultats parall√®les.
   */
  private async rerankDocs(
    query: string,
    docs: Document[],
    fileIds: string[],
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    llm: BaseChatModel,
    hasUploadedDocs: boolean = false
  ) {
    console.log('üîç Mode d\'optimisation:', optimizationMode);
    console.log('üîç Query pour la recherche d\'image:', query);

    // √âviter de refaire des recherches si les documents contiennent d√©j√† des r√©sultats web
    const hasWebResults = docs.some(doc => doc.metadata?.type === 'web');
    const hasExpertResults = docs.some(doc => doc.metadata?.type === 'expert');
    
    // Si nous avons d√©j√† des r√©sultats web et experts, enrichir seulement avec des images si n√©cessaire
    if (hasWebResults && (hasExpertResults || !this.config.searchDatabase)) {
      console.log('üîç R√©utilisation des r√©sultats web et experts existants');
      
      let enrichedDocs = docs;
      // Toujours chercher des images quel que soit le mode d'optimisation
      console.log('üîç Recherche d\'image (simplifi√©e) ind√©pendamment du mode d\'optimisation');
      const images = await this.handleImageSearch(query, llm);
      if (images && images.length > 0) {
        console.log('üîç Image trouv√©e et ajout√©e aux r√©sultats existants');
        enrichedDocs = docs.map(doc => ({
          ...doc,
          metadata: {
            ...doc.metadata,
            illustrationImage: images[0].img_src,
            imageTitle: images[0].title
          }
        }));
      }
      
      return enrichedDocs.slice(0, 15);
    }

    const { images, experts, webResults } = await this.parallelSearchOperations(
      query,
      llm,
      embeddings,
      optimizationMode,
      hasUploadedDocs
    );

    let enrichedDocs = docs;
    if (images && images.length > 0) {
      console.log('üîç Premi√®re image trouv√©e:', {
        src: images[0].img_src,
        title: images[0].title,
        url: images[0].url
      });
      enrichedDocs = docs.map(doc => ({
        ...doc,
        metadata: {
          ...doc.metadata,
          illustrationImage: images[0].img_src,
          imageTitle: images[0].title
        }
      }));
    }
    return [
      ...enrichedDocs,
      ...experts,
      ...webResults
    ].slice(0, 15);
  }

  /**
   * Pr√©paration optimis√©e des documents pour l'analyse.
   */
  private prepareDocumentsForAnalysis(
    docs: Document[],
    message: string
  ): Document[] {
    console.log('üìö Pr√©paration des documents pour analyse');
    // Ajouter un contexte sur la requ√™te en cours √† chaque document
    return docs.map(doc => {
      return new Document({
        pageContent: doc.pageContent,
        metadata: {
          ...doc.metadata,
          queryContext: message.substring(0, 100), // Ajouter un contexte de requ√™te limit√©
          analysisDate: new Date().toISOString()
        }
      });
    });
  }

  /**
   * M√©thode principale qui g√®re la recherche et la g√©n√©ration de r√©ponse.
   */
  async searchAndAnswer(
    message: string,
    history: BaseMessage[],
    llm: BaseChatModel,
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    fileIds: string[]
  ) {
    const emitter = new EventEmitter();
    this._currentEmitter = emitter; // Stocker l'√©metteur courant
    console.log(`[MetaSearch] Nouvelle requ√™te re√ßue. Mode: ${optimizationMode}, Fichiers: ${fileIds.length}`);

    try {
      this.updateMemory(new HumanMessage(message));
      const mergedHistory: BaseMessage[] = [
        ...this.conversationHistory,
        ...history,
      ];

      // D√©terminer si on tente l'analyse directe Gemini
      const modelName = (llm as any).modelName as string | undefined;
      const hasFiles = fileIds.length > 0;
      const isGemini15 = modelName?.includes('gemini-1.5');
      const isGemini20Flash = modelName?.includes('gemini-2.0-flash');
      
      const useGeminiDirectAnalysis = hasFiles && modelName && (isGemini15 || isGemini20Flash);

      if (useGeminiDirectAnalysis) {
        console.log('[MetaSearch] üîç Tentative analyse directe avec Gemini...');
        try {
          const docs = await this.analyzeDocumentsWithGemini(fileIds, message, llm);
          console.log(`[MetaSearch] R√©sultat analyse directe: ${docs.length} documents.`);
          
          if (docs.length > 0) {
            // Envoyer les sources (simplifi√©)
            emitter.emit(
              'data',
              JSON.stringify({
                type: 'sources',
                data: docs.map(doc => ({ metadata: doc.metadata })) // Envoyer juste les m√©tadonn√©es
              })
            );
            
            // Cr√©er la cha√Æne de r√©ponse principale
            const answeringChain = await this.createAnsweringChain(
              llm,
              fileIds, // Important de passer les fileIds pour le contexte
              embeddings,
              optimizationMode
            );
            
            // G√©n√©rer la r√©ponse en utilisant les docs de Gemini
            console.log('[MetaSearch] G√©n√©ration r√©ponse bas√©e sur analyse Gemini...');
            const stream = answeringChain.streamEvents(
              {
                chat_history: mergedHistory,
                query: message // Utiliser le message original comme query
              },
              { version: 'v1' }
            );
            
            this.handleStreamWithMemory(stream, emitter, llm, message);
            return emitter; // Sortir car l'analyse directe a fonctionn√©
          } else {
            console.log(`[MetaSearch] Analyse directe Gemini n'a retourn√© aucun document, passage au fallback.`);
          }
        } catch (error) {
          console.error('[MetaSearch] ‚ùå Erreur analyse directe Gemini:', error);
          console.log('[MetaSearch] ‚ö†Ô∏è Retour √† la m√©thode standard.');
        }
      } else if (hasFiles) { // Modifi√© pour √™tre plus clair: on a des fichiers mais pas le bon mod√®le
          console.log('[MetaSearch] ‚ÑπÔ∏è Mod√®le non compatible pour analyse directe Gemini ou erreur nom mod√®le.');
      }

      // --- Fallback ou cas sans analyse directe --- 
      console.log('[MetaSearch] Utilisation du chemin standard (Recherche Web/Experts si applicable)...');
      
      // Appel standard √† la cha√Æne de r√©ponse qui g√®re interneement web/expert
      const answeringChain = await this.createAnsweringChain(
        llm,
        fileIds, // Passer fileIds m√™me si vide, la logique interne g√®re
        embeddings,
        optimizationMode
      );

      const stream = answeringChain.streamEvents(
        {
          chat_history: mergedHistory,
          query: message
        },
        { version: 'v1' }
      );
      this.handleStreamWithMemory(stream, emitter, llm, message);

    } catch (error) {
      console.error('[MetaSearch] ‚ùå ERREUR MAJEURE searchAndAnswer:', error);
      emitter.emit('error', JSON.stringify({ type: 'error', data: 'Erreur interne du serveur.' }));
      emitter.emit('end');
    }
    
    // Nettoyer la r√©f√©rence
    this._currentEmitter = null;
    
    return emitter;
  }

  /**
   * M√©thode de secours en cas d'erreur lors de la recherche document√©e.
   * NOTE: Cette m√©thode pourrait devenir moins pertinente avec l'approche Gemini directe,
   * mais gard√©e pour l'instant pour les erreurs non li√©es √† l'analyse directe.
   */
  private async handleFallback(
    llm: BaseChatModel,
    message: string,
    history: BaseMessage[],
    emitter: EventEmitter,
    fileIds: string[],
    embeddings: Embeddings,
    mode: 'speed' | 'balanced' | 'quality'
  ) {
    console.log('[MetaSearch] Appel de la m√©thode Fallback...');
    try {
      const answeringChain = await this.createAnsweringChain(
        llm,
        fileIds,
        embeddings,
        mode
      );
      
      const stream = answeringChain.streamEvents(
        {
          chat_history: history,
          query: message
        },
        { version: 'v1' }
      );
      this.handleStreamWithMemory(stream, emitter, llm, message);
    } catch (fallbackError) {
      console.error('[MetaSearch] ‚ùå ERREUR dans handleFallback:', fallbackError);
      emitter.emit('error', JSON.stringify({ type: 'error', data: 'Erreur interne (fallback) du serveur.' }));
      emitter.emit('end');
    }
  }

  /**
   * V√©rifie et initialise le vectorStore si n√©cessaire.
   */
  private async ensureVectorStoreInitialized(documents: Document[], embeddings: Embeddings): Promise<RAGDocumentChain> {
    const ragChain = RAGDocumentChain.getInstance();
    try {
      const hasDocuments = ragChain.isInitialized();
      if (!hasDocuments) {
        console.log('üîÑ Initialisation du vector store avec les documents...');
        await ragChain.initializeVectorStoreFromDocuments(documents, embeddings);
      } else {
        console.log('‚úÖ Vector store d√©j√† initialis√© avec des documents');
      }
      return ragChain;
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'initialisation du vector store:', error);
      throw error;
    }
  }
}

export const searchHandlers: Record<string, MetaSearchAgentType> = {
  legal: {
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds
    ) => {
      const emitter = new EventEmitter();
      try {
        const mergedHistory: BaseMessage[] = history;
        const chain = RAGDocumentChain.getInstance();
        await chain.initializeVectorStoreFromDocuments(
          fileIds.map(fileId => new Document({
            pageContent: '',
            metadata: { source: fileId }
          })),
          embeddings
        );
        const searchChain = chain.createSearchChain(llm);
        const results = await searchChain.invoke({
          query: message,
          chat_history: mergedHistory,
          type: 'legal'
        });
        const response: SearchResponse = {
          text: results,
          sources: []
        };
        emitter.emit(
          'data',
          JSON.stringify({
            type: 'response',
            data: response.text
          })
        );
        emitter.emit('end');
      } catch (error) {
        emitter.emit(
          'error',
          JSON.stringify({
            type: 'error',
            data: error.message
          })
        );
      }
      return emitter;
    }
  },
  documents: {
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds
    ) => {
      const emitter = new EventEmitter();
      try {
        const chain = RAGDocumentChain.getInstance();
        await chain.initializeVectorStoreFromDocuments(
          fileIds.map(fileId => new Document({
            pageContent: '',
            metadata: { source: fileId }
          })),
          embeddings
        );
        const searchChain = chain.createSearchChain(llm);
        const results = await searchChain.invoke({
          query: message,
          chat_history: history,
          type: 'documents'
        });
        const response: SearchResponse = {
          text: results,
          sources: []
        };
        emitter.emit(
          'data',
          JSON.stringify({
            type: 'response',
            data: response.text
          })
        );
        emitter.emit('end');
      } catch (error) {
        emitter.emit(
          'error',
          JSON.stringify({
            type: 'error',
            data: error.message
          })
        );
      }
      return emitter;
    }
  },
  uploads: {
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds
    ) => {
      const emitter = new EventEmitter();
      try {
        // Analyse de la requ√™te pour en d√©duire l'intention
        const queryIntent = await llm.invoke(`
Analysez cette requ√™te et d√©terminez son intention principale :
1. SUMMARY (demande de r√©sum√© ou synth√®se globale)
2. ANALYSIS (demande d'analyse ou d'explication)
3. SPECIFIC (question sp√©cifique sur le contenu)
4. COMPARE (demande de comparaison)

Requ√™te : "${message}"

R√©pondez uniquement avec l'intention.
        `);
        const intent = String(queryIntent.content).trim();
        console.log('üéØ Intention d√©tect√©e:', intent);

        const docsArrays = await Promise.all(
          fileIds.map(async (fileId) => {
            const filePath = path.join(process.cwd(), 'uploads', fileId);
            const contentPath = `${filePath}-extracted.json`;
            await fs.promises.access(contentPath);
            const contentData = await fs.promises.readFile(contentPath, 'utf8');
            const content = JSON.parse(contentData);
            const chunkSize = 1000;
            const overlap = 100;
            const chunks: string[] = [];
            let currentChunk = '';
            let currentSize = 0;
            content.contents.forEach((text: string) => {
              currentChunk += text + ' ';
              currentSize += text.length;
              if (currentSize >= chunkSize) {
                chunks.push(currentChunk);
                currentChunk = currentChunk.slice(-overlap);
                currentSize = overlap;
              }
            });
            if (currentChunk) {
              chunks.push(currentChunk);
            }
            return chunks.map((chunk, index) => {
              const pageNumber = Math.floor(index / (chunks.length / (content.pageCount || 1))) + 1;
              return new Document({
                pageContent: chunk,
                metadata: {
                  title: content.title || 'Document sans titre',
                  source: fileId,
                  type: 'uploaded',
                  url: `/viewer/${fileId}?page=${pageNumber}`,
                  pageNumber,
                  chunkIndex: index,
                  totalChunks: chunks.length,
                  searchText: chunk.substring(0, 100).replace(/[\n\r]+/g, ' ').trim()
                }
              });
            });
          })
        );
        const flatDocs = docsArrays.flat();
        console.log('üìö Nombre total de chunks:', flatDocs.length);

        const ragChain = RAGDocumentChain.getInstance();
        await ragChain.initializeVectorStoreFromDocuments(flatDocs, embeddings);
        const chain = ragChain.createSearchChain(llm);

        let queryPrompt = message;
        switch (intent) {
          case 'SUMMARY':
            queryPrompt = 'Fais un r√©sum√© complet et structur√© de ce document en te concentrant sur les points cl√©s';
            break;
          case 'ANALYSIS':
            queryPrompt = `Analyse en d√©tail les aspects suivants du document concernant : ${message}. Fournis une analyse structur√©e avec des exemples du texte.`;
            break;
          case 'SPECIFIC':
            queryPrompt = `En te basant sur le contenu du document, r√©ponds pr√©cis√©ment √† cette question : ${message}`;
            break;
          case 'COMPARE':
            queryPrompt = `Compare et analyse en d√©tail les diff√©rents aspects concernant : ${message}. Structure ta r√©ponse par points de comparaison.`;
            break;
        }

        const stream = await chain.streamEvents(
          {
            query: queryPrompt,
            chat_history: history,
            type: intent.toLowerCase()
          },
          { version: 'v1' }
        );

        let sourcesEmitted = false;
        for await (const event of stream) {
          if (event.event === 'on_chain_stream') {
            emitter.emit(
              'data',
              JSON.stringify({
                type: 'response',
                data: event.data.chunk
              })
            );
          }
          if (!sourcesEmitted && event.event === 'on_chain_start') {
            const sources = flatDocs.slice(0, 5).map(doc => ({
              title: doc.metadata?.title || '',
              content: doc.metadata?.searchText || '',
              url: doc.metadata?.url,
              source: doc.metadata?.source,
              type: 'uploaded',
              pageNumber: doc.metadata?.pageNumber
            }));
            emitter.emit(
              'data',
              JSON.stringify({
                type: 'sources',
                data: sources
              })
            );
            sourcesEmitted = true;
          }
          if (event.event === 'on_chain_end') {
            emitter.emit('end');
          }
        }
      } catch (error) {
        console.error('Erreur lors de la recherche dans les documents:', error);
        emitter.emit(
          'error',
          JSON.stringify({
            type: 'error',
            data: error.message
          })
        );
      }
      return emitter;
    }
  }
};

export default MetaSearchAgent;